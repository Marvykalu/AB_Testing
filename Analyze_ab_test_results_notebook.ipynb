{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze A/B Test Results\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists. As a part of the student working towards obtaining a Data Analyst Nano-degree program in Udacity, it is important that I get some practice working with the difficulties of these A/B tests. \n",
    "\n",
    "The objective of this project is to understand the results of an A/B test run by an e-commerce website. I will work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Now, read in the `ab_data.csv` data. Store it in `df`. \n",
    "\n",
    "a. Read in the dataset and take a look at the top few rows here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 294478 number of rows in the dataset\n"
     ]
    }
   ],
   "source": [
    "print('There are {}'.format(df.shape[0]), 'number of rows in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give the number of unique users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 290584 unique users in the dataset\n"
     ]
    }
   ],
   "source": [
    "print('There are {}'.format(df['user_id'].nunique()),'unique users in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### What is the proportion of users converted.\n",
    "\n",
    "Here we basically calculate the proportion of 1's to 0's (or mean) in the coversion column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Give the number of times the `new_page` and `treatment` don't match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways the new_page and treatment don't match.\n",
    "\n",
    "1) group = treatment and landing_page = old_page\n",
    "\n",
    "2) group = control and landing_page = new_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_group = df['group']=='treatment'\n",
    "new_landing_page = df['landing_page'] == 'new_page'\n",
    "\n",
    "#For treatment == new_page == false, that is when treatment don't match new_page\n",
    "#we will store the result in the dataset treatment_newpage\n",
    "\n",
    "treatment_newpage = df[(treatment_group== new_landing_page)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times new_page and treatment don't match is 3893\n"
     ]
    }
   ],
   "source": [
    "#what is the dimension of the treatment_newpage dataframe?\n",
    "\n",
    "print('The number of times new_page and treatment don\\'t match is {}'.format(treatment_newpage.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do any of the rows have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       294478 non-null  int64 \n",
      " 1   timestamp     294478 non-null  object\n",
      " 2   group         294478 non-null  object\n",
      " 3   landing_page  294478 non-null  object\n",
      " 4   converted     294478 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in the rows\n"
     ]
    }
   ],
   "source": [
    "print('There are no missing values in the rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How should we handle the rows where **treatment** does not match with **new_page** or **control** does not match with **old_page**.  \n",
    "\n",
    "a. Removing these rows is the best thing to do.\n",
    "\n",
    "Let us now create a new dataset df2 that stores only rows where treatment and new_page meet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The new datafame df2 will contain only the treatment group and new landing page. That is where treatment and new_page macth.\n",
    "\n",
    "- We expect that the size of df2 must be 3893 less than the size of our original dataframe df. This is because 3893 is the numberof times treatment don't match with new page as we already calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new datafame has 290585 rows\n"
     ]
    }
   ],
   "source": [
    "#For treatment == new_page == True, that is when treatment match new_page\n",
    "#we will store the result in the dataset df2\n",
    "\n",
    "df2 = df[(treatment_group == new_landing_page) == True]\n",
    "\n",
    "#check to make sure size of df2 is 3893 less than size df\n",
    "\n",
    "print('The new datafame has {}'.format(df2.shape[0]),'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many unique **user_id**s are in **df2**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 290584 unique users in the new dataset df2\n"
     ]
    }
   ],
   "source": [
    "print('There are {}'.format(df2['user_id'].nunique()), 'unique users in the new dataset df2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### There is one **user_id** repeated in **df2**.  What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check which user information was duplicated\n",
    "\n",
    "df2[df2['user_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So information about user with user_id 773192 was repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the row information for the repeat **user_id**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get information about the repeated user id\n",
    "\n",
    "df2.query('user_id==773192')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user_id is 773192, under the treatment group in the new landing page\n"
     ]
    }
   ],
   "source": [
    "print('The user_id is 773192, under the treatment group in the new landing page')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove **one** of the rows with a duplicate **user_id**, but keep your dataframe as **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.drop([1899],inplace=True)\n",
    "\n",
    "\n",
    "#confirm that the number of rows in df2 is now 1 number short, that is 290854\n",
    "df2.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the new dataset df2.\n",
    "\n",
    "a. What is the probability of an individual converting regardless of the page they receive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regardless of the page received, the probability an individual converting is 0.11959708724499628\n"
     ]
    }
   ],
   "source": [
    "#We calculate the propotion of 1's to 0's, \n",
    "#that is the mean in converted column \n",
    "\n",
    "convert_mean = df2['converted'].mean()\n",
    "\n",
    "print('Regardless of the page received, the probability an individual converting is {}'.format(convert_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that an individual in the control group got converted is 0.1203863045004612\n"
     ]
    }
   ],
   "source": [
    "#filter data set to include only control group\n",
    "control_df = df2.query('group ==\"control\"')['converted']\n",
    "\n",
    "#probability converted\n",
    "\n",
    "control_prob = control_df.mean()\n",
    "\n",
    "print('The probability that an individual in the control group got converted is {}'.format(control_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that an individual in the treatment group got converted is 0.11880806551510564\n"
     ]
    }
   ],
   "source": [
    "#filter data set to include only control group\n",
    "treatment_df = df2.query('group ==\"treatment\"')['converted']\n",
    "\n",
    "#probability converted\n",
    "\n",
    "treat_prob = treatment_df.mean()\n",
    "\n",
    "print('The probability that an individual in the treatment group got converted is {}'.format(treat_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observed difference from our statistics is -0.0015782389853555567\n"
     ]
    }
   ],
   "source": [
    "#the observed difference in conversion between the two groups\n",
    "obs_diff = (treat_prob - control_prob)\n",
    "\n",
    "\n",
    "print(\"The observed difference from our statistics is {}\".format(obs_diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that an individual received the new page is 0.5000619442226688\n"
     ]
    }
   ],
   "source": [
    "new_p = df2.query('landing_page ==\"new_page\"').count()[0]/df2.shape[0]\n",
    "\n",
    "print('The probability that an individual received the new page is {}'.format(new_p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the treatment page leads to more conversions?\n",
    "\n",
    "Considering our results from parts (a) through (d) above, explain below whether we think there is sufficient evidence to conclude that the new treatment page leads to more conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the original dataframe, we find that the average conversion rate regardless of the page an individual recieved is $11.96\\%$.\n",
    "\n",
    "- Now if an individual was found in the new page (that is the treatment group), the coversion rate is $11.88 \\%$ which is $0.08\\%$ less than the overall conversion rate.\n",
    "\n",
    "- Similarly if an individual was found in the old page (which is aligned with the control group), the conversion rate is $12.04\\%$ which is $0.08\\%$ greater than the overall conversion rate.\n",
    "\n",
    "Looking at the conversion rate above, one would say it is not worth putting resources into the new page as the old page has higher conversion rate. However, the difference in conversion rate between the old page and new page could be insignificant (about $0.16\\%$), and we could conclude that it could be chance. How do we know this? We could benefit from more testing. A  look at how long the test was run;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2017-01-02 13:42:05.378582', '2017-01-24 13:41:54.460509')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us look at how long the test was run for\n",
    "\n",
    "df['timestamp'].min(), df['timestamp'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shows that the test was run for 22 days (about 3 weeks), a sufficient amount of time. Hence there is no sufficient evidence that the new treatment page leads to more conversion, and we believe the old page has more conversion at this point until proven not true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Notice that because of the time stamp associated with each event, we could technically run a hypothesis test continuously as each observation was observed.  \n",
    "\n",
    "However, then the hard question is do we stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  How long do you run to render a decision that neither page is better than another?  \n",
    "\n",
    "These questions are the difficult parts associated with A/B tests in general.  \n",
    "\n",
    "\n",
    "`1.` For now, let us consider we might need to make the decision just based on all the data provided.  If we want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, \n",
    "\n",
    "#### What should your null and alternative hypotheses be?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of words or in terms of **$p_{old}$** and **$p_{new}$**, which are the converted rates for the old and new pages, our null and alternative hypothesis are\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "H_{0}: & \\text{ The new page is worse than or as good as the old page}\\\\\n",
    "&p_{new} - p_{old} \\leq 0 \\\\\n",
    "H_{1}: &\\text{ The new page is better than the old page}\\\\\n",
    "& p_{new} - p_{old} > 0 \n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "Use a sample size for each page equal to the ones in **ab_data.csv**.  <br><br>\n",
    "\n",
    "Perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{aligned}\n",
    "H_{0}: p_{new} - p_{old} = 0 \\\\\n",
    "H_{1}: p_{new} - p_{old} \\neq 0 \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So our new hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. What is the **conversion rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_pnew = df2['converted'].mean()\n",
    "rate_pnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What is the **conversion rate** for $p_{old}$ under the null? <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_pold = df2['converted'].mean()\n",
    "rate_pold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is $n_{new}$, the number of individuals in the treatment group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_new = df2.query('group == \"treatment\"')['user_id'].count()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is $n_{old}$, the number of individuals in the control group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_old = df2.query('group == \"control\"')['user_id'].count()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simulation below, rate_new is the proportion of users in df2.shape[0] (the population of users from which the sample was drawn) who would convert to new_page. The number of users who would convert to new_page in a simulation of size $n_{new}$ has the binomial distribution with parameters $n_{new}$ and rate_new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_page_converted = np.random.binomial(1, rate_pnew, n_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_page_converted = np.random.binomial(1, rate_pold, n_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in sample population is 0.001347006377419191\n"
     ]
    }
   ],
   "source": [
    "diffs = new_page_converted.mean() - old_page_converted.mean()\n",
    "print('Difference in sample population is {}'.format(diffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create 10,000 $p_{new}$ - $p_{old}$ values using the same simulation process we used in parts (a) through (g) above. \n",
    "\n",
    "Store all 10,000 values in a NumPy array called **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_converted_simulation = np.random.binomial(n_new, rate_pnew,  10000)/n_new\n",
    "old_converted_simulation = np.random.binomial(n_old, rate_pold,  10000)/n_old\n",
    "p_diffs = new_converted_simulation - old_converted_simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "\n",
    "Plot a histogram of the **p_diffs**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_diffs = np.array(p_diffs)\n",
    "\n",
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central limit theory says that with a large enough sample size, our sample mean follows a normal distribution. The plot looks to me like a normal distribution, which is what we expect to see given our large sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view 99% confidence interval\n",
    "low, upper = np.percentile(p_diffs, 2.5), np.percentile(p_diffs, 97.5)\n",
    "plt.hist(p_diffs);\n",
    "plt.axvline(x=low, color='red', linewidth=2);\n",
    "plt.axvline(x=upper, color='red', linewidth=2);\n",
    "plt.axvline(obs_diff, color='yellow', linewidth=2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper bound of the 95% percentile is 0.0023448030445004007\n",
      "\n",
      "Lower bound of the 95% percentile is -0.002390296734398408\n",
      "\n",
      "Observed difference in our population parameter is -0.0015782389853555567\n"
     ]
    }
   ],
   "source": [
    "print('Upper bound of the 95% percentile is {}'.format(upper))\n",
    "print('\\nLower bound of the 95% percentile is {}'.format(low))\n",
    "print('\\nObserved difference in our population parameter is {}'.format(obs_diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a significance (alpha) level of $0.05$ (that is a $5\\%$ chance of making a Type 1 error), our confidence level is $95\\%$. We see from the plot that our null hypothesis value is contained within the confidence interval, suggesting that our null hypothesis did generate our statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-value\n",
    "\n",
    "#### What proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proportion of p_diffs greater than observed (p-value): 0.9049\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProportion of p_diffs greater than observed (p-value): {}\".format ((p_diffs > obs_diff).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "What we computed in part j is known as p-value; which is defined as probability that we have falsely rejected the null hypothesis.\n",
    "\n",
    "What do we expect of this p-value? Since we did not reject the null hypothesis, we expect that the p-value should be high. \n",
    "\n",
    "In principle, given that our significance level $\\alpha = 0.05$, the following conditions apply\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "p \\leq\\alpha : & \\text{ evidence to reject the null hypothesis}\\\\\n",
    "p > \\alpha: &\\text{ fail to reject the null hypothesis}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "From our computation, our p = $0.903 > \\alpha$ is large, thus there is no evidence against the null hypothesis and we hold on to our belief that 'that the old page has equal conversion rate than the new page'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using computer built-in statistical models\n",
    "\n",
    "We could also use a built-in to achieve similar results.  Though using the built-in might be easier to code, the portions we have shown above are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have calculated n_new and n_old already, we will calculate the number of conversion for each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_old_convert = df2.query(\"landing_page == 'old_page'\")['converted'].sum()\n",
    "no_new_convert = df2.query(\"landing_page == 'new_page'\")['converted'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test statistics and p-value\n",
    "\n",
    "We will use `stats.proportions_ztest` to compute your test statistic and p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score, p_value = sm.stats.proportions_ztest([no_old_convert, no_new_convert], [n_old, n_new], value=None, alternative='smaller', prop_var=False) \n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do the z-score and p-value you computed in the previous question mean for the conversion rates of the old and new pages?  Do they agree with the findings in parts **j.** and **k.**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By definition,\n",
    "\n",
    "The z-score (which is a measure of standard deviation) is a test of statistical significance that helps us decide whether or not to reject the null hypothesis. \n",
    "\n",
    "Now since we used a $95\\%$ confidence interval, \n",
    "\n",
    "- the critical z-score values are $-1.96$ and $+1.96$ standard deviations and the p-value associated with this confidence level as we have discussed is $0.05$.\n",
    "\n",
    "- If our z-score lies within the critical z-score values, the p-value will be greater than $0.05$ and you will fail to reject the null hypothesis.\n",
    "\n",
    "\n",
    "Our computation shows that our z-score is $~1.311$ which is within the z-score critical values, hence we have p-value $~0.905 > 0.05$, hence we fail to reject the null hypothesis that old page and new page has equal conversion rate.  \n",
    "\n",
    "We see that the p-value obtained from the z-test agrees with the p-value obtained earlier on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "In this final part, we will see that the result we achieved in the A/B test in Part II above can also be achieved by performing regression.<br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that since each row is either a conversion or no conversion, that is our response variable is a categorical variable with two possible outcomes (conversion or no coversion), we apply the logistic regression to model our regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to use **statsmodels** to fit the logistic regression model to see if there is a significant difference in conversion based on which page a customer receives. To achieve this,\n",
    "\n",
    "- we will create in df2 a column for the intercept, \n",
    "\n",
    "- we will also create a dummy variable column for which page each user received: **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>control</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  new_page  old_page  control  ab_page  \n",
       "0          1         0         1        1        0  \n",
       "1          1         0         1        1        0  \n",
       "2          1         1         0        0        1  \n",
       "3          1         1         0        0        1  \n",
       "4          1         0         1        1        0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding an intercept column\n",
    "df2['intercept'] = 1\n",
    "\n",
    "#creating our dummy variables\n",
    "df2[['new_page', 'old_page']] = pd.get_dummies(df2['landing_page'])\n",
    "df2[['control', 'ab_page']] = pd.get_dummies(df2['group'])\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **statsmodels** to instantiate our regression model on the intercept and ab_page columns we created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#fitting our logistic regression model\n",
    "\n",
    "logit_mod = sm.Logit(df2['converted'], df2[['intercept', 'ab_page']])\n",
    "results = logit_mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide the summary of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 20 Jul 2020</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:17:05</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Mon, 20 Jul 2020   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        09:17:05   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "Here there is an inverse relationship between conversion and group of a customer. In other words, the probability of conversion is higher for customers in the control group (our baseline) as compared to treatment group.\n",
    "\n",
    "#### Odd ratio:\n",
    "So, np.exp($\\beta_{0}$) = 1/exp(−1.9888) = 7.31 is the chance of conversion among those customers that are in the control group holding all variables constant.\n",
    "\n",
    "likewise we expect the probability of a customer in the treatment group converting to decrease by (1/np.exp(-0.0150) = 1.015 ), all variables kept constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why does the p-value associated with  **ab_page** differ from the value found in **Part II**? What are the null and alternative hypotheses associated with our regression model, and how do they compare to the null and alternative hypotheses in **Part II**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer\n",
    "\n",
    "The explanatory variable in this model is group, which we have coded using an indicator variable with values ab_page = 1 for treatment group and control 0 for control group. The response variable, conversion, is also an indicator variable. Thus, each customer either converts to new page or does not convert to new page. The model says that the probability, p, that a customer would convert depends upon the customer's group (ab_page = 1 or control = 0). So there are two possible values for p—say, p_new and p_old.\n",
    "\n",
    "- The p-value associated with intercept is $0.00$ which is less than $0.05$ the significance ($\\alpha$) value, hence it is statistically significant in predicting whether the customer converts or not. Likewise the p-value associated with ab_page is $0.19$ and since it is larger than the significance ($\\alpha$) level of  $0.05$, shows us that the landing page is not statistically significant in predicting whether the customer converts or not. Here the null and alternative hypothesis for the slope $\\beta_1$ or intercep $\\beta_{0}$ for the regression are respectively:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_{0}: \\beta_{i} = 0\\\\\n",
    "H_{1}: \\beta_{i} \\neq 0 \n",
    "\\end{aligned}\n",
    "$$\n",
    "which strictly attempts to predicts a differece in the two values, \n",
    "\n",
    "- When we look at the p-value found in Part II, we see a huge difference. This is because the null and alternative hypotheses there were respectively\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_{0}: \\leq 0\\\\\n",
    "H_{1}: > 0 \n",
    "\\end{aligned}\n",
    "$$\n",
    "which aims to predict which page gets more conversions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there other things that might influence whether or not an individual converts? Is it appropraiate to add these variables to our model? What possible setbacks might we encounter?\n",
    "\n",
    "Variable like countries where an individual lives in might influence conversion rate.\n",
    "When we consider multiple explanatroy variables for our regression model, we are more likely to draw a better conlusion based on our observations. So far, it does not appear that we have a siginifcant evidence whether a user in the treatment or control group converts or not. Therefore, it is probably a good idea to see whether other factors might predict conversion. \n",
    "\n",
    "We would have to ensure that the additional terms are\n",
    "\n",
    "1) correlated with the response variable (a linear relationship)\n",
    "\n",
    "2) not correlated or similar to each other.\n",
    "\n",
    "Also we would have to transform any non-linear features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing another explanatory variable (country where users live in)\n",
    "\n",
    "Now along with testing if the conversion rate changes for different pages, lets us also add an effect based on which country a user lives in. \n",
    "\n",
    "A dataset **countries.csv'** with a list of countries are provided. We will read this dataset and merge the result with our df2 dataset. \n",
    "\n",
    "#### Does it appear that country had an impact on conversion?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df = pd.read_csv('./countries.csv')\n",
    "countries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>control</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  new_page  old_page  control  ab_page  \n",
       "user_id                                                              \n",
       "834778           0          1         0         1        1        0  \n",
       "928468           0          1         1         0        0        1  \n",
       "822059           1          1         1         0        0        1  \n",
       "711597           0          1         0         1        1        0  \n",
       "710616           0          1         1         0        0        1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = countries_df.set_index('user_id').join(df2.set_index('user_id'\n",
    "), how='inner')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UK', 'US', 'CA'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review country column data, how many unique entries are there?\n",
    "df3['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>control</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  new_page  old_page  control  ab_page  CA  UK  \\\n",
       "user_id                                                                       \n",
       "834778           0          1         0         1        1        0   0   1   \n",
       "928468           0          1         1         0        0        1   0   0   \n",
       "822059           1          1         1         0        0        1   0   1   \n",
       "711597           0          1         0         1        1        0   0   1   \n",
       "710616           0          1         1         0        0        1   0   1   \n",
       "\n",
       "         US  \n",
       "user_id      \n",
       "834778    0  \n",
       "928468    1  \n",
       "822059    0  \n",
       "711597    0  \n",
       "710616    0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the necessary dummy variables\n",
    "\n",
    "df3[['CA', 'UK', 'US']] = pd.get_dummies(df3['country'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 20 Jul 2020</td> <th>  Pseudo R-squ.:     </th>  <td>1.521e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:18:21</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1984</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9967</td> <td>    0.007</td> <td> -292.314</td> <td> 0.000</td> <td>   -2.010</td> <td>   -1.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.518</td> <td> 0.129</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.746</td> <td> 0.456</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Mon, 20 Jul 2020   Pseudo R-squ.:               1.521e-05\n",
       "Time:                        09:18:21   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1984\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9967      0.007   -292.314      0.000      -2.010      -1.983\n",
       "CA            -0.0408      0.027     -1.518      0.129      -0.093       0.012\n",
       "UK             0.0099      0.013      0.746      0.456      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df3['converted'], df3[['intercept', 'CA', 'UK']])\n",
    "results = logit_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With p-values that are greater than the signifcance ($\\alpha$) level of 0.05, it does not appear that country has a significant impact on conversion.\n",
    "\n",
    "However, customers who live in Canada (CA) are (1/np.exp(-0.048)) = 1.04 times less likely to convert compared to customers who live in the United States (US), while customers who live in the United Kingdom are np.exp(0.0099) = 1.01 more likely to convert than customers living in the US."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though you have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion.  Create the necessary additional columns, and fit the new model.  \n",
    "\n",
    "Provide the summary results, and your conclusions based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 20 Jul 2020</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:18:23</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Mon, 20 Jul 2020   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        09:18:23   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "CA            -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "UK             0.0099      0.013      0.743      0.457      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mod3 = sm.Logit(df3['converted'], df3[['intercept', 'ab_page', 'CA', 'UK']])\n",
    "results = logit_mod3.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With p-values that are greater than the signifcance ($\\alpha$) level of 0.05, it does not appear that interaction between country and landing page has a significant impact on conversion rate.\n",
    "\n",
    "Since there is no linear relationship here, one last thing we could consider to be sure of our conclusion is adding higher order terms to our list of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>control</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>UK_new_page</th>\n",
       "      <th>US_new_page</th>\n",
       "      <th>CA_new_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  new_page  old_page  control  ab_page  CA  UK  \\\n",
       "user_id                                                                       \n",
       "834778           0          1         0         1        1        0   0   1   \n",
       "928468           0          1         1         0        0        1   0   0   \n",
       "822059           1          1         1         0        0        1   0   1   \n",
       "711597           0          1         0         1        1        0   0   1   \n",
       "710616           0          1         1         0        0        1   0   1   \n",
       "\n",
       "         US  UK_new_page  US_new_page  CA_new_page  \n",
       "user_id                                             \n",
       "834778    0            0            0            0  \n",
       "928468    1            0            1            0  \n",
       "822059    0            1            0            0  \n",
       "711597    0            0            0            0  \n",
       "710616    0            1            0            0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['UK_new_page'] = df3['UK']*df3['ab_page']\n",
    "df3['US_new_page'] = df3['US']*df3['ab_page']\n",
    "df3['CA_new_page'] = df3['CA']*df3['ab_page']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 20 Jul 2020</td> <th>  Pseudo R-squ.:     </th>  <td>2.364e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:18:24</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.08085</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>   <td>   -1.9963</td> <td>    0.006</td> <td> -322.049</td> <td> 0.000</td> <td>   -2.008</td> <td>   -1.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_new_page</th> <td>   -0.0752</td> <td>    0.038</td> <td>   -1.997</td> <td> 0.046</td> <td>   -0.149</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_new_page</th> <td>    0.0149</td> <td>    0.017</td> <td>    0.862</td> <td> 0.389</td> <td>   -0.019</td> <td>    0.049</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Mon, 20 Jul 2020   Pseudo R-squ.:               2.364e-05\n",
       "Time:                        09:18:24   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.08085\n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "intercept      -1.9963      0.006   -322.049      0.000      -2.008      -1.984\n",
       "CA_new_page    -0.0752      0.038     -1.997      0.046      -0.149      -0.001\n",
       "UK_new_page     0.0149      0.017      0.862      0.389      -0.019       0.049\n",
       "===============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking US as baseline\n",
    "\n",
    "logit_mod = sm.Logit(df3['converted'], df3[['intercept', 'CA_new_page', 'UK_new_page']])\n",
    "results = logit_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0780997492739288, 1.0150115583846535)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.exp(-0.0752), np.exp(0.0149)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for Canada (CA), the p-value has improved to be almost statistically significant for predicting our response. This shows that adding higher terms could help us predict our response rightly. \n",
    "\n",
    "Overall the difference we observe are quite insignificant: Here we notice that users living in CA are 1.078 times less likely to convert to a new page compared to users living in the US. Similarly, users in the UK are 1.015 times more likely to convert than users in US. This tells us that users in Canada have change aversion and users in the UK are more drwan to change. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
